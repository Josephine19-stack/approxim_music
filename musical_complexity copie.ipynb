{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import Counter\n",
    "import math\n",
    "import zlib\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import mido\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"music_metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(notes_dict):\n",
    "    pitches = [note[0] for note in notes_dict.values()]\n",
    "    durations = [note[1] for note in notes_dict.values()]\n",
    "    velocities = [note[2] for note in notes_dict.values()]\n",
    "    return pitches, durations, velocities\n",
    "def calculate_entropy(sequence):\n",
    "    counts = Counter(sequence)\n",
    "    probabilities = [count / len(sequence) for count in counts.values()]\n",
    "    return -sum(p * math.log2(p) for p in probabilities if p > 0)\n",
    "def calculate_compression_ratio(sequence):\n",
    "    # Convert the sequence to a string for compression\n",
    "    sequence_str = \",\".join(map(str, sequence))\n",
    "    compressed = zlib.compress(sequence_str.encode('utf-8'))\n",
    "    return len(compressed) / len(sequence_str.encode('utf-8'))\n",
    "\n",
    "def calculate_metrix(df):\n",
    "    complexity_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        notes_dict = ast.literal_eval(row[\"Notes\"])  # Convert string back to dictionary\n",
    "        pitches, durations, velocities = extract_features(notes_dict)\n",
    "\n",
    "        metrics = {\n",
    "        \"pitch_entropy\": calculate_entropy(pitches),\n",
    "        \"duration_entropy\": calculate_entropy(durations),\n",
    "        \"velocity_entropy\": calculate_entropy(velocities),\n",
    "        \"pitch_compression\": calculate_compression_ratio(pitches),\n",
    "        \"duration_compression\": calculate_compression_ratio(durations),\n",
    "        \"velocity_compression\": calculate_compression_ratio(velocities),\n",
    "        }\n",
    "\n",
    "        complexity_scores.append(metrics)\n",
    "\n",
    "    # Add the complexity column to the dataframe\n",
    "    return complexity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: Metrix, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(output_directory)\n",
    "df[\"Metrix\"] = calculate_metrix(df)\n",
    "print(df[\"Metrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_notes_from_df(df):\n",
    "    # Crée trois nouvelles colonnes pour les pitches, durations et velocities\n",
    "    df[\"pitches\"] = df[\"Notes\"].apply(lambda x: [note[0] for note in ast.literal_eval(x).values()])\n",
    "    df[\"durations\"] = df[\"Notes\"].apply(lambda x: [note[1] for note in ast.literal_eval(x).values()])\n",
    "    df[\"velocities\"] = df[\"Notes\"].apply(lambda x: [note[2] for note in ast.literal_eval(x).values()])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = extract_notes_from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/env_TP2/lib/python3.12/site-packages/pandas/core/indexes/range.py:413\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_range\u001b[39m.\u001b[39;49mindex(new_key)\n\u001b[1;32m    414\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#l = [df[\"pitches\"][0],df[\"durations\"][0],df[\"velocities\"][0]]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(df[\u001b[39m\"\u001b[39;49m\u001b[39mpitches\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m]) \u001b[39m#df[\"pitches\"] est en 2D\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_TP2/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1123\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_TP2/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1239\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_TP2/lib/python3.12/site-packages/pandas/core/indexes/range.py:415\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range\u001b[39m.\u001b[39mindex(new_key)\n\u001b[1;32m    414\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 415\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    417\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#l = [df[\"pitches\"][0],df[\"durations\"][0],df[\"velocities\"][0]]\n",
    "\n",
    "\n",
    "print(df[\"pitches\"][0][0]) #df[\"pitches\"] est en 2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'y a que des partitions de piano dans le dataset, une seule piste à chaque morceau/ligne (donc ce qu'on voulait nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Je veux des listes des triplets \n",
    "\n",
    "\n",
    "def extract_triplets(df):\n",
    "    \"\"\"\n",
    "    Convert the 'Notes' column in the DataFrame into a list of triplets (pitches, durations, velocities).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a 'Notes' column with dictionary-like strings.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with a new column 'triplets' containing the list of tuples.\n",
    "    \"\"\"\n",
    "    df[\"triplets\"] = df[\"Notes\"].apply(lambda x: [tuple(note) for note in ast.literal_eval(x).values()])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_triplets(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On encode notre musique en une séquence de mots, écrits en bits. Les mots sont séparés par des espaces.**\n",
    "\n",
    "Séquence : position - p - d - v\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approche de la complexité de Kolmogorov\n",
    "En gros une note c'est un triplet (p,d,v) (pitch, duratio,velocity)\n",
    "Donc deux notes identiques c'est deux notes qui ont les mêmes p,d,v\n",
    "Si on a deux mêmes p,d,v alors on a juste à écrire la note une fois, et à mettre ses 2 emplacements. C'est moins long que d'encoder deux fois l'emplacement et le p,d,v. Donc premier facteur de réduction de complexité\n",
    "\n",
    "\n",
    "Savoir qu'il y a plusieurs notes de même p ça sert pas forcément à grand chose car il faut quand même noter leur emplacement\n",
    "Mais quand plusieurs notes de même p ou d ou v se suivent la c'est intéressant et ça fait diminuer la complexité\n",
    "Donc quand on a des notes qui se suivent avec mêmes p ou d ou v, complexité diminue\n",
    "\n",
    "pareil si c'est pour des couples de var : si deux notes se suivent avec même p,v (mais d différent) alors ça fait quand même bien diminuer la complexité \n",
    "Algo : \n",
    "\n",
    "1) on imagine que notre code code toutes les notes uniques et sans aucunes répetitions de p,d,v à droite ou à gauche, avec leurs emplacements\n",
    "\n",
    "2) puis il prend celles qui se répètentsur une ou 2 vars, et les codes ensemble\n",
    "\n",
    "3) puis il prend les notes identiques et code juste leur emplacement\n",
    "\n",
    "Si une note est à la fois exactement égale à une autre, et apparait dans une répétition de p, alors comment on l'encode ? Ca c'est une bonne question (elle appartient aux notes de catégorie 2 et 3 à la fois)\n",
    "-> Pour l'instant on considère que la méthode 3 est toujours plus efficace, donc on classe ce genre de note dans la classe 3\n",
    "\n",
    "--> En vérité ça va dépendre de la longueur de la répétition d'une var. Si ça fait beaucoup diminuer la complexité des notes voisines alors il faudrait prendre encodage 2. Mais y a aussi un problème avec cette espèce de \"valeur\" de complexité. On fait des +1 -1 genre ?\n",
    "\n",
    "Pour l'instant oui "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus long encodage : chaque triplet et son emplacement "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taille de l'encodage d'un triplet (𝑝,𝑑,𝑣) : constante 𝐶_note\n",
    "Taille de l'encodage de la position : constant 𝐶_position\n",
    "nombre de notes : n \n",
    "Taille maximale de l'encodage : n x (𝐶_note + 𝐶_position) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108.610510805501\n",
      "9824\n"
     ]
    }
   ],
   "source": [
    "mean_length = np.mean([len(df[\"triplets\"][i]) for i in range(len(df[\"triplets\"]))])\n",
    "print(mean_length)\n",
    "\n",
    "max_length = np.max([len(df[\"triplets\"][i]) for i in range(len(df[\"triplets\"]))])\n",
    "print(max_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taille encodage p : p varie de 0 à 127, il est donc écrit sur 7 bits\n",
    "\n",
    "d en millisecondes, ne dépasse pas 10 000 ms :  14 bits\n",
    "\n",
    "v varie de 0 à 127 : 7 bits\n",
    "\n",
    "𝐶_note = 28 bits\n",
    "\n",
    "la partition la plus longue comporte : 9824 notes\n",
    "9824 se code sur 14 bits\n",
    "donc la position se code sur 14 bits\n",
    "\n",
    "𝐶_position = 14 bits\n",
    "\n",
    "Taille maximale de l'encodage = n x 42 bits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séquence :  p - d - v - position\n",
    "Soit :      7   14  7      14       en bits\n",
    "\n",
    "Si on voit plusieurs séquences de 14 bits d'affilées, c'est qu'on a un triplet identique à plusieurs endroits, et qu'on encode à la suite les positions\n",
    "\n",
    "(peut-être que ce serait bien de préciser la position que dans ce cas d'ailleurs, car sinon la suite se lit comme une séquence, les notes sont codées les unes après les autres selon leur ordre d'apparition, donc on connait déjà leur position)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il faut avoir une manière de préciser dans le code qu’on a une répétition et la taille de la répétition. Il y a 5 types de répétitions possibles : d, p , v ou de doublets (p,v) , (p,d) (d,v), ça se code sur 4 bits. Ca tombe bien rien ne fait 4 bits dans ce qui précéde, donc dans notre code cès qu'on voit 4 bits, ça veut dire qu'il y a répétition. Ca dit qu'est-ce qui est répété. Puis ensuite ça donne le nombre de répétitions. Pas sur que ce 'quand tu vois un mot de 4 bits c'est que c'est pour préciser une répétition donc tu sais ce que ça veut dire' soit très correct. On suppose que les mots sont séparés par des espaces. Est-ce qu'on peut faire cette hypothèse ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = df[\"triplets\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': [[0, 1], [3, 4, 5]], 'd': [[0, 1], [3, 4, 5]], 'v': [[0, 1], [3, 4, 5]], 'p_v': [[0, 1], [3, 4, 5]], 'p_d': [[0, 1], [3, 4, 5]], 'd_v': [[0, 1], [3, 4, 5]]}\n"
     ]
    }
   ],
   "source": [
    "def detect_continuous_repetitions(triplets):\n",
    "    \"\"\"\n",
    "    Détecte les répétitions contiguës dans une liste de triplets (p, d, v) \n",
    "    et les classe par type de répétition.\n",
    "    \n",
    "    Args:\n",
    "        triplets (list of tuples): Liste des notes sous forme de triplets (p, d, v).\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionnaire contenant les répétitions détectées sous forme de listes d'indices.\n",
    "    \"\"\"\n",
    "    repetitions = {\n",
    "        \"p\": [],       # Répétitions de pitches\n",
    "        \"d\": [],       # Répétitions de durations\n",
    "        \"v\": [],       # Répétitions de velocities\n",
    "        \"p_v\": [],     # Répétitions de (p, v)\n",
    "        \"p_d\": [],     # Répétitions de (p, d)\n",
    "        \"d_v\": []      # Répétitions de (d, v)\n",
    "    }\n",
    "    \n",
    "    n = len(triplets)\n",
    "    \n",
    "    # Fonction pour détecter les répétitions sur une clé donnée\n",
    "    def detect_repetition(key_func):\n",
    "        result = []\n",
    "        start = 0  # Début d'une répétition\n",
    "        for i in range(1, n):\n",
    "            if key_func(triplets[i]) == key_func(triplets[i - 1]):\n",
    "                continue  # La répétition continue\n",
    "            else:\n",
    "                # Fin de la répétition\n",
    "                if i - start > 1:  # Une répétition doit avoir au moins 2 éléments\n",
    "                    result.append(list(range(start, i)))\n",
    "                start = i  # Nouvelle répétition\n",
    "        # Ajouter la dernière répétition\n",
    "        if n - start > 1:\n",
    "            result.append(list(range(start, n)))\n",
    "        return result\n",
    "    \n",
    "    # Appliquer la détection pour chaque type\n",
    "    repetitions[\"p\"] = detect_repetition(lambda t: t[0])  # Répétitions sur p\n",
    "    repetitions[\"d\"] = detect_repetition(lambda t: t[1])  # Répétitions sur d\n",
    "    repetitions[\"v\"] = detect_repetition(lambda t: t[2])  # Répétitions sur v\n",
    "    repetitions[\"p_v\"] = detect_repetition(lambda t: (t[0], t[2]))  # Répétitions sur (p, v)\n",
    "    repetitions[\"p_d\"] = detect_repetition(lambda t: (t[0], t[1]))  # Répétitions sur (p, d)\n",
    "    repetitions[\"d_v\"] = detect_repetition(lambda t: (t[1], t[2]))  # Répétitions sur (d, v)\n",
    "    \n",
    "    return repetitions\n",
    "\n",
    "triplets = [(55, 305, 84), (55, 305, 84),(74, 600, 120),(55, 305, 84),(55, 305, 84),(55, 305, 84)]\n",
    "\n",
    "dico_repet = detect_continuous_repetitions(triplets)\n",
    "\n",
    "print(dico_repet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p_d': [], 'd_v': [[0, 1], [3, 4, 5]], 'p_v': [], 'p': [], 'd': [], 'v': []}\n"
     ]
    }
   ],
   "source": [
    "def detect_prioritized_repetitions(partition):\n",
    "    \"\"\"\n",
    "    Détecte les répétitions contiguës de doublets (p, d), (p, v), (d, v) \n",
    "    et les répétitions simples dans une liste de partition.\n",
    "    \"\"\"\n",
    "    repetitions = {\n",
    "        \"p_d\": [],\n",
    "        \"d_v\": [],\n",
    "        \"p_v\": [],\n",
    "        \"p\": [],\n",
    "        \"d\": [],\n",
    "        \"v\": []\n",
    "    }\n",
    "\n",
    "    n = len(partition)\n",
    "    used_indices = set()\n",
    "\n",
    "    def detect_repetition(key_func, existing_indices):\n",
    "        result = []\n",
    "        start = 0\n",
    "        for i in range(1, n):\n",
    "            if key_func(partition[i]) == key_func(partition[i - 1]) and i not in existing_indices:\n",
    "                continue\n",
    "            else:\n",
    "                if i - start > 1 and not any(j in existing_indices for j in range(start, i)):\n",
    "                    result.append(list(range(start, i)))\n",
    "                start = i\n",
    "        if n - start > 1 and not any(j in existing_indices for j in range(start, n)):\n",
    "            result.append(list(range(start, n)))\n",
    "        return result\n",
    "\n",
    "    # Détection des doublets\n",
    "    repetitions[\"p_d\"] = detect_repetition(lambda t: (t[0], t[1]), used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"p_d\"] for idx in group])\n",
    "\n",
    "    repetitions[\"d_v\"] = detect_repetition(lambda t: (t[1], t[2]), used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"d_v\"] for idx in group])\n",
    "\n",
    "    repetitions[\"p_v\"] = detect_repetition(lambda t: (t[0], t[2]), used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"p_v\"] for idx in group])\n",
    "\n",
    "    # Détection des répétitions simples\n",
    "    repetitions[\"p\"] = detect_repetition(lambda t: t[0], used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"p\"] for idx in group])\n",
    "\n",
    "    repetitions[\"d\"] = detect_repetition(lambda t: t[1], used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"d\"] for idx in group])\n",
    "\n",
    "    repetitions[\"v\"] = detect_repetition(lambda t: t[2], used_indices)\n",
    "\n",
    "    return repetitions\n",
    "\n",
    "#TEST\n",
    "\n",
    "partition = [(56, 305, 85), (55, 305, 85),(74, 600, 120),(53, 305, 85),(54, 305, 85),(51, 305, 85)]\n",
    "\n",
    "dico_repet = detect_prioritized_repetitions(partition)\n",
    "\n",
    "print(dico_repet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(74, 600, 120, 4), (51, 305, 85, 42)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def traiter_same_notes(partition):\n",
    "    \"\"\"\n",
    "    Détecte les triplets présents au moins deux fois dans la liste,\n",
    "    renvoie un dictionnaire avec leur nombre d'occurrences\n",
    "    et une liste sans aucune occurrence des triplets répétés.\n",
    "\n",
    "    Args:\n",
    "        partition (list of tuples): Liste des triplets (p, d, v).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionnaire avec les triplets répétés comme clés et leur occurrence comme valeurs.\n",
    "        list: Liste des triplets sans aucune occurrence des répétitions.\n",
    "    \"\"\"\n",
    "    # Etape 1 : créer la liste des triplets \n",
    "    liste_triplets = [quadruplet[:3] for quadruplet in partition]\n",
    "\n",
    "    # Étape 1 : Compter les occurrences de chaque triplet\n",
    "\n",
    "    compteur = Counter(liste_triplets)\n",
    "    \n",
    "    # Étape 2 : Construire un dictionnaire des triplets ayant des occurrences >= 2\n",
    "    dico_repetitions = {triplet: count for triplet, count in compteur.items() if count >= 2}\n",
    "    \n",
    "    # Étape 3 : Construire une nouvelle liste en excluant les triplets dupliqués\n",
    "    nouvelle_partition = [quadruplet for quadruplet in partition if quadruplet[:3] not in dico_repetitions]\n",
    "    \n",
    "    return dico_repetitions, nouvelle_partition\n",
    "\n",
    "\n",
    "\n",
    "partition = [(55, 305, 85,1), (55, 305, 85,2),(74, 600, 120,4),(55, 305, 85,8),(55, 305, 85,12),(51, 305, 85,42)]\n",
    "\n",
    "dico,liste = traiter_same_notes(partition)\n",
    "\n",
    "print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code harmonique\n",
    "#On doit le faire avant le reste\n",
    "\n",
    "def algo_harmoniques(partition) :\n",
    "    # Initialisation\n",
    "    dico_accords = {}  # Dictionnaire pour stocker les accords et leur valeur associée\n",
    "    valeur_incr = 128  # Valeur de départ pour les accords\n",
    "    partition_accords = []  # Liste pour stocker la nouvelle partition avec accords\n",
    "    gain_total = 0  # Variable pour stocker le gain total\n",
    "\n",
    "    # Regrouper les quadruplets par start_time\n",
    "    accords_par_temps = defaultdict(list)\n",
    "    for quadruplet in partition:\n",
    "        pitch, duration, velocity, start_time = quadruplet\n",
    "        accords_par_temps[start_time].append(quadruplet)\n",
    "\n",
    "    # Parcourir les accords regroupés\n",
    "    for start_time, notes in accords_par_temps.items():\n",
    "        if len(notes) > 1:  # Il s'agit d'un accord si plusieurs notes partagent le même start_time\n",
    "            # Créer un tuple représentant l'accord (les pitches triés pour garantir l'unicité)\n",
    "            pitches = tuple(sorted(note[0] for note in notes))\n",
    "\n",
    "            # Ajouter l'accord au dictionnaire s'il n'existe pas\n",
    "            if pitches not in dico_accords:\n",
    "                dico_accords[pitches] = valeur_incr\n",
    "                valeur_incr += 1\n",
    "\n",
    "            # Calculer le gain pour cet accord\n",
    "            gain = 20 * (len(notes) - 1)\n",
    "            gain_total += gain\n",
    "\n",
    "            # Créer un seul quadruplet pour l'accord\n",
    "            duration = notes[0][1]  # Prendre la duration de la première note\n",
    "            velocity = notes[0][2]  # Prendre la velocity de la première note\n",
    "            partition_accords.append((dico_accords[pitches], duration, velocity, start_time))\n",
    "        else:\n",
    "            # Garder les notes seules inchangées\n",
    "            partition_accords.append(notes[0])\n",
    "\n",
    "    # Remplacer la partition originale\n",
    "    partition = partition_accords\n",
    "\n",
    "    return partition,gain_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estim_complexite(partition) :\n",
    "    \"\"\" partition : liste de tuples de 3 int. Chaque tuple représente une note\n",
    "    Cette fonction estime la complexité de la partition, à partir des hypothèses émises précédemment\n",
    "    \"\"\"\n",
    "    worst_complexity = 42*len(partition) #Comme expliqué plus haut \n",
    "    #On commence par les accords\n",
    "    partition,gain_accords = algo_harmoniques(partition)\n",
    "    #détecter les triplets identiques\n",
    "    same_triplets,partition_reduite = traiter_same_notes(partition)\n",
    "    #On utilisera le dictionnaire same_triplets, pour calculer la réduction de complexité, après\n",
    "\n",
    "    #détecter les répétitions de d, p , v ou de doublets (p,v),(p,d) (d,v)\n",
    "    repetitions = detect_prioritized_repetitions(partition_reduite)\n",
    "\n",
    "    #Maintenant on va utiliser nos deux dictionnaires 'same_triplets' et repetitions pour calculer la réduction de complexité\n",
    "\n",
    "    #On commence par les triplets identiques \n",
    "    gain_triplets_identiques = sum((count - 1) * 28 for count in same_triplets.values())\n",
    "\n",
    "    #Maintenant gain sur les répétitions de doublet ou simple variable\n",
    "    # Définition des économies par type\n",
    "    gains_par_type = {\n",
    "        \"p\": 7,\n",
    "        \"d\": 14,\n",
    "        \"v\": 7,\n",
    "        \"p_d\": 21,\n",
    "        \"p_v\": 14,\n",
    "        \"d_v\": 21\n",
    "    }\n",
    "    \n",
    "    gain_repetitions = 0\n",
    "    \n",
    "    # Boucle sur chaque type de répétition\n",
    "    for type_repet, repetitions in repetitions.items():\n",
    "        for repetition in repetitions:\n",
    "            taille = len(repetition)  # Taille de la répétition\n",
    "            if taille > 1:  # Les répétitions doivent être d'au moins 2 notes\n",
    "                # Calcul des bits économisés pour cette répétition\n",
    "                bits_economises = (taille - 1) * gains_par_type[type_repet]\n",
    "                \n",
    "                # Bits pour encoder le type (4 bits) et la taille (log2(taille))\n",
    "                bits_ajoutes = 4 + math.ceil(math.log2(taille))\n",
    "                \n",
    "                # Gain net\n",
    "                gain_net = bits_economises - bits_ajoutes\n",
    "                gain_repetitions += gain_net\n",
    "\n",
    "    \n",
    "    #Et le calcul final\n",
    "    Complexity = worst_complexity - gain_triplets_identiques - gain_repetitions - gain_accords\n",
    "\n",
    "    return Complexity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explication des calculs**\n",
    "**Pour les triplets identiques :** \n",
    "\n",
    "On doit coder le triplet une seule fois, puis les positions. La complexité est alors de :\n",
    "C = 28 + 14 x nb_repetition_du_triplet. On économise 28 bits à chaque fois qu'on a un triplet identique en +. On encode 1 fois pour tous les nb_repetition_du_triplet de la partition. Donc on gagne 28x(nb_repetition_du_triplet - 1). Pour chaque triplet répété.\n",
    "\n",
    "**Pour les répétitions de doublets ou simples variables :**\n",
    "\n",
    "On doit coder de quel type de répétition il s'agit. 6 types de répétition possibles, donc cette info se code sur 4 bits. C'est d'ailleurs le seul mot de 4 bits possible dans notre séquence, donc quand on voit un mot de 4 bits on sait qu'on a à faire à une répétition. Il faut aussi encoder la taille de la répétition : sur combien de notes la répétition a lieu. Cette valeur vaut log2(taille_répétition). En fonction de la ou les variables qui se répètent on économise plus ou moins de bits. p fait 7 bits donc les répétitions de p économisent 7 bits à chaque fois (moins tous ceux qu'on a du ajouter pour encoder la répétition). Pour une répétition de d on économise 14 bits à chaque fois. Pour des doublets on économise sur chaque variable. Si on a une répétion d_p, on économise 7 + 14 = 21 bits par répétition. On encode donc cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Tests\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m partition_test \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mtriplets\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mComplexité estimée\u001b[39m\u001b[39m\"\u001b[39m,estim_complexite(partition_test))\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mworst_case complexity = \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m42\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(partition_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Tests\n",
    "partition_test = df[\"triplets\"][0]\n",
    "\n",
    "\n",
    "print(\"Complexité estimée\",estim_complexite(partition_test))\n",
    "print(\"worst_case complexity = \",42*len(partition_test))\n",
    "\n",
    "print(\"ratio de compression via ma méthode = \",(estim_complexite(partition_test))/(42*len(partition_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul de la compression zip\n",
    "\n",
    "def calculer_ratio_compression(partition):\n",
    "    \"\"\"\n",
    "    Calcule le ratio de compression d'une partition de triplets en utilisant zlib.\n",
    "\n",
    "    Args:\n",
    "        partition (list of tuples): Liste de triplets (p, d, v).\n",
    "\n",
    "    Returns:\n",
    "        float: Ratio de compression (valeur entre 0 et 1, où plus proche de 0 = meilleure compression).\n",
    "    \"\"\"\n",
    "    # Étape 1 : Convertir la partition en chaîne de caractères\n",
    "    partition_str = \",\".join(f\"{t[0]}_{t[1]}_{t[2]}\" for t in partition)\n",
    "    \n",
    "    # Étape 2 : Compresser la chaîne avec zlib\n",
    "    partition_bytes = partition_str.encode('utf-8')  # Conversion en bytes\n",
    "    compressed_bytes = zlib.compress(partition_bytes)\n",
    "    \n",
    "    # Étape 3 : Calculer le ratio de compression\n",
    "    ratio_compression = len(compressed_bytes) / len(partition_bytes)\n",
    "    \n",
    "    return ratio_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexité estimée 27298\n",
      "worst_case complexity =  55944\n",
      "ratio de compression via ma méthode =  0.48795223795223797\n",
      "ratio de compression avec zip =  0.08481277040131284\n"
     ]
    }
   ],
   "source": [
    "#Tests\n",
    "partition_test = df[\"triplets\"][0]\n",
    "\n",
    "\n",
    "print(\"Complexité estimée\",estim_complexite(partition_test))\n",
    "print(\"worst_case complexity = \",42*len(partition_test))\n",
    "\n",
    "print(\"ratio de compression via ma méthode = \",(estim_complexite(partition_test))/(42*len(partition_test)))\n",
    "print(\"ratio de compression avec zip = \",calculer_ratio_compression(partition_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[\"Notes\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mido import MidiFile\n",
    "\n",
    "# Fonction pour extraire les notes au format (p, d, v, t)\n",
    "def extract_note_data(midi_path):\n",
    "    note_data = []\n",
    "    midi = MidiFile(midi_path)\n",
    "    current_time = 0  # Temps accumulé en ticks\n",
    "    for track in midi.tracks:\n",
    "        for msg in track:\n",
    "            if not msg.is_meta:\n",
    "                current_time += msg.time  # Temps accumulé\n",
    "                if msg.type == 'note_on' and msg.velocity > 0:\n",
    "                    note_data.append((msg.note, 0, msg.velocity, current_time))\n",
    "    return note_data\n",
    "\n",
    "# Parcourir tous les fichiers MIDI\n",
    "extract_path = \"adl-piano-midi\"\n",
    "all_notes = []\n",
    "\n",
    "for root, _, files in os.walk(extract_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mid\") or file.endswith(\".midi\"):\n",
    "            midi_path = os.path.join(root, file)\n",
    "            notes = extract_note_data(midi_path)\n",
    "            all_notes.extend([(file, note) for note in notes])\n",
    "\n",
    "# Afficher un aperçu des notes extraites\n",
    "print(\"Exemple de notes extraites :\")\n",
    "print(all_notes[:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problème : on a en réalité 4 variables, donc on doit refaire un dataset accurate. On essaie dans un nouveau Notebook**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partition : c'est une liste de triplets \n",
    "\n",
    "On s'en fout de la nature du triplet, tant qu'on a 3 valeurs\n",
    "\n",
    "On va juste convertir les bonnes données, en triplet. Et voila \n",
    "\n",
    "Pour les harmoniques, quand y'a un delta_t à 0 ça veut dire 2 notes sont jouées en même temps. Si ça correspond à un accord, alors on encode le nom de l'accord à la place des deux notes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_TP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dac106c35ce3d047d16e564b0a4c64d2054fbff410f883fbe9cca57677e1729f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
