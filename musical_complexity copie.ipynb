{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import Counter\n",
    "import math\n",
    "import zlib\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import mido\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"music_metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(notes_dict):\n",
    "    pitches = [note[0] for note in notes_dict.values()]\n",
    "    durations = [note[1] for note in notes_dict.values()]\n",
    "    velocities = [note[2] for note in notes_dict.values()]\n",
    "    return pitches, durations, velocities\n",
    "def calculate_entropy(sequence):\n",
    "    counts = Counter(sequence)\n",
    "    probabilities = [count / len(sequence) for count in counts.values()]\n",
    "    return -sum(p * math.log2(p) for p in probabilities if p > 0)\n",
    "def calculate_compression_ratio(sequence):\n",
    "    # Convert the sequence to a string for compression\n",
    "    sequence_str = \",\".join(map(str, sequence))\n",
    "    compressed = zlib.compress(sequence_str.encode('utf-8'))\n",
    "    return len(compressed) / len(sequence_str.encode('utf-8'))\n",
    "\n",
    "def calculate_metrix(df):\n",
    "    complexity_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        notes_dict = ast.literal_eval(row[\"Notes\"])  # Convert string back to dictionary\n",
    "        pitches, durations, velocities = extract_features(notes_dict)\n",
    "\n",
    "        metrics = {\n",
    "        \"pitch_entropy\": calculate_entropy(pitches),\n",
    "        \"duration_entropy\": calculate_entropy(durations),\n",
    "        \"velocity_entropy\": calculate_entropy(velocities),\n",
    "        \"pitch_compression\": calculate_compression_ratio(pitches),\n",
    "        \"duration_compression\": calculate_compression_ratio(durations),\n",
    "        \"velocity_compression\": calculate_compression_ratio(velocities),\n",
    "        }\n",
    "\n",
    "        complexity_scores.append(metrics)\n",
    "\n",
    "    # Add the complexity column to the dataframe\n",
    "    return complexity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: Metrix, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(output_directory)\n",
    "df[\"Metrix\"] = calculate_metrix(df)\n",
    "print(df[\"Metrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_notes_from_df(df):\n",
    "    # Cr√©e trois nouvelles colonnes pour les pitches, durations et velocities\n",
    "    df[\"pitches\"] = df[\"Notes\"].apply(lambda x: [note[0] for note in ast.literal_eval(x).values()])\n",
    "    df[\"durations\"] = df[\"Notes\"].apply(lambda x: [note[1] for note in ast.literal_eval(x).values()])\n",
    "    df[\"velocities\"] = df[\"Notes\"].apply(lambda x: [note[2] for note in ast.literal_eval(x).values()])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = extract_notes_from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/env_TP2/lib/python3.12/site-packages/pandas/core/indexes/range.py:413\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_range\u001b[39m.\u001b[39;49mindex(new_key)\n\u001b[1;32m    414\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#l = [df[\"pitches\"][0],df[\"durations\"][0],df[\"velocities\"][0]]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(df[\u001b[39m\"\u001b[39;49m\u001b[39mpitches\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m]) \u001b[39m#df[\"pitches\"] est en 2D\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_TP2/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1123\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_TP2/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1239\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env_TP2/lib/python3.12/site-packages/pandas/core/indexes/range.py:415\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range\u001b[39m.\u001b[39mindex(new_key)\n\u001b[1;32m    414\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 415\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    417\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#l = [df[\"pitches\"][0],df[\"durations\"][0],df[\"velocities\"][0]]\n",
    "\n",
    "\n",
    "print(df[\"pitches\"][0][0]) #df[\"pitches\"] est en 2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'y a que des partitions de piano dans le dataset, une seule piste √† chaque morceau/ligne (donc ce qu'on voulait nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Je veux des listes des triplets \n",
    "\n",
    "\n",
    "def extract_triplets(df):\n",
    "    \"\"\"\n",
    "    Convert the 'Notes' column in the DataFrame into a list of triplets (pitches, durations, velocities).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a 'Notes' column with dictionary-like strings.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with a new column 'triplets' containing the list of tuples.\n",
    "    \"\"\"\n",
    "    df[\"triplets\"] = df[\"Notes\"].apply(lambda x: [tuple(note) for note in ast.literal_eval(x).values()])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_triplets(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On encode notre musique en une s√©quence de mots, √©crits en bits. Les mots sont s√©par√©s par des espaces.**\n",
    "\n",
    "S√©quence : position - p - d - v\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approche de la complexit√© de Kolmogorov\n",
    "En gros une note c'est un triplet (p,d,v) (pitch, duratio,velocity)\n",
    "Donc deux notes identiques c'est deux notes qui ont les m√™mes p,d,v\n",
    "Si on a deux m√™mes p,d,v alors on a juste √† √©crire la note une fois, et √† mettre ses 2 emplacements. C'est moins long que d'encoder deux fois l'emplacement et le p,d,v. Donc premier facteur de r√©duction de complexit√©\n",
    "\n",
    "\n",
    "Savoir qu'il y a plusieurs notes de m√™me p √ßa sert pas forc√©ment √† grand chose car il faut quand m√™me noter leur emplacement\n",
    "Mais quand plusieurs notes de m√™me p ou d ou v se suivent la c'est int√©ressant et √ßa fait diminuer la complexit√©\n",
    "Donc quand on a des notes qui se suivent avec m√™mes p ou d ou v, complexit√© diminue\n",
    "\n",
    "pareil si c'est pour des couples de var : si deux notes se suivent avec m√™me p,v (mais d diff√©rent) alors √ßa fait quand m√™me bien diminuer la complexit√© \n",
    "Algo : \n",
    "\n",
    "1) on imagine que notre code code toutes les notes uniques et sans aucunes r√©petitions de p,d,v √† droite ou √† gauche, avec leurs emplacements\n",
    "\n",
    "2) puis il prend celles qui se r√©p√®tentsur une ou 2 vars, et les codes ensemble\n",
    "\n",
    "3) puis il prend les notes identiques et code juste leur emplacement\n",
    "\n",
    "Si une note est √† la fois exactement √©gale √† une autre, et apparait dans une r√©p√©tition de p, alors comment on l'encode ? Ca c'est une bonne question (elle appartient aux notes de cat√©gorie 2 et 3 √† la fois)\n",
    "-> Pour l'instant on consid√®re que la m√©thode 3 est toujours plus efficace, donc on classe ce genre de note dans la classe 3\n",
    "\n",
    "--> En v√©rit√© √ßa va d√©pendre de la longueur de la r√©p√©tition d'une var. Si √ßa fait beaucoup diminuer la complexit√© des notes voisines alors il faudrait prendre encodage 2. Mais y a aussi un probl√®me avec cette esp√®ce de \"valeur\" de complexit√©. On fait des +1 -1 genre ?\n",
    "\n",
    "Pour l'instant oui "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus long encodage : chaque triplet et son emplacement "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taille de l'encodage d'un triplet (ùëù,ùëë,ùë£) : constante ùê∂_note\n",
    "Taille de l'encodage de la position : constant ùê∂_position\n",
    "nombre de notes : n \n",
    "Taille maximale de l'encodage : n x (ùê∂_note + ùê∂_position) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108.610510805501\n",
      "9824\n"
     ]
    }
   ],
   "source": [
    "mean_length = np.mean([len(df[\"triplets\"][i]) for i in range(len(df[\"triplets\"]))])\n",
    "print(mean_length)\n",
    "\n",
    "max_length = np.max([len(df[\"triplets\"][i]) for i in range(len(df[\"triplets\"]))])\n",
    "print(max_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taille encodage p : p varie de 0 √† 127, il est donc √©crit sur 7 bits\n",
    "\n",
    "d en millisecondes, ne d√©passe pas 10 000 ms :  14 bits\n",
    "\n",
    "v varie de 0 √† 127 : 7 bits\n",
    "\n",
    "ùê∂_note = 28 bits\n",
    "\n",
    "la partition la plus longue comporte : 9824 notes\n",
    "9824 se code sur 14 bits\n",
    "donc la position se code sur 14 bits\n",
    "\n",
    "ùê∂_position = 14 bits\n",
    "\n",
    "Taille maximale de l'encodage = n x 42 bits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S√©quence :  p - d - v - position\n",
    "Soit :      7   14  7      14       en bits\n",
    "\n",
    "Si on voit plusieurs s√©quences de 14 bits d'affil√©es, c'est qu'on a un triplet identique √† plusieurs endroits, et qu'on encode √† la suite les positions\n",
    "\n",
    "(peut-√™tre que ce serait bien de pr√©ciser la position que dans ce cas d'ailleurs, car sinon la suite se lit comme une s√©quence, les notes sont cod√©es les unes apr√®s les autres selon leur ordre d'apparition, donc on connait d√©j√† leur position)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il faut avoir une mani√®re de pr√©ciser dans le code qu‚Äôon a une r√©p√©tition et la taille de la r√©p√©tition. Il y a 5 types de r√©p√©titions possibles : d, p , v ou de doublets (p,v) , (p,d) (d,v), √ßa se code sur 4 bits. Ca tombe bien rien ne fait 4 bits dans ce qui pr√©c√©de, donc dans notre code c√®s qu'on voit 4 bits, √ßa veut dire qu'il y a r√©p√©tition. Ca dit qu'est-ce qui est r√©p√©t√©. Puis ensuite √ßa donne le nombre de r√©p√©titions. Pas sur que ce 'quand tu vois un mot de 4 bits c'est que c'est pour pr√©ciser une r√©p√©tition donc tu sais ce que √ßa veut dire' soit tr√®s correct. On suppose que les mots sont s√©par√©s par des espaces. Est-ce qu'on peut faire cette hypoth√®se ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = df[\"triplets\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': [[0, 1], [3, 4, 5]], 'd': [[0, 1], [3, 4, 5]], 'v': [[0, 1], [3, 4, 5]], 'p_v': [[0, 1], [3, 4, 5]], 'p_d': [[0, 1], [3, 4, 5]], 'd_v': [[0, 1], [3, 4, 5]]}\n"
     ]
    }
   ],
   "source": [
    "def detect_continuous_repetitions(triplets):\n",
    "    \"\"\"\n",
    "    D√©tecte les r√©p√©titions contigu√´s dans une liste de triplets (p, d, v) \n",
    "    et les classe par type de r√©p√©tition.\n",
    "    \n",
    "    Args:\n",
    "        triplets (list of tuples): Liste des notes sous forme de triplets (p, d, v).\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionnaire contenant les r√©p√©titions d√©tect√©es sous forme de listes d'indices.\n",
    "    \"\"\"\n",
    "    repetitions = {\n",
    "        \"p\": [],       # R√©p√©titions de pitches\n",
    "        \"d\": [],       # R√©p√©titions de durations\n",
    "        \"v\": [],       # R√©p√©titions de velocities\n",
    "        \"p_v\": [],     # R√©p√©titions de (p, v)\n",
    "        \"p_d\": [],     # R√©p√©titions de (p, d)\n",
    "        \"d_v\": []      # R√©p√©titions de (d, v)\n",
    "    }\n",
    "    \n",
    "    n = len(triplets)\n",
    "    \n",
    "    # Fonction pour d√©tecter les r√©p√©titions sur une cl√© donn√©e\n",
    "    def detect_repetition(key_func):\n",
    "        result = []\n",
    "        start = 0  # D√©but d'une r√©p√©tition\n",
    "        for i in range(1, n):\n",
    "            if key_func(triplets[i]) == key_func(triplets[i - 1]):\n",
    "                continue  # La r√©p√©tition continue\n",
    "            else:\n",
    "                # Fin de la r√©p√©tition\n",
    "                if i - start > 1:  # Une r√©p√©tition doit avoir au moins 2 √©l√©ments\n",
    "                    result.append(list(range(start, i)))\n",
    "                start = i  # Nouvelle r√©p√©tition\n",
    "        # Ajouter la derni√®re r√©p√©tition\n",
    "        if n - start > 1:\n",
    "            result.append(list(range(start, n)))\n",
    "        return result\n",
    "    \n",
    "    # Appliquer la d√©tection pour chaque type\n",
    "    repetitions[\"p\"] = detect_repetition(lambda t: t[0])  # R√©p√©titions sur p\n",
    "    repetitions[\"d\"] = detect_repetition(lambda t: t[1])  # R√©p√©titions sur d\n",
    "    repetitions[\"v\"] = detect_repetition(lambda t: t[2])  # R√©p√©titions sur v\n",
    "    repetitions[\"p_v\"] = detect_repetition(lambda t: (t[0], t[2]))  # R√©p√©titions sur (p, v)\n",
    "    repetitions[\"p_d\"] = detect_repetition(lambda t: (t[0], t[1]))  # R√©p√©titions sur (p, d)\n",
    "    repetitions[\"d_v\"] = detect_repetition(lambda t: (t[1], t[2]))  # R√©p√©titions sur (d, v)\n",
    "    \n",
    "    return repetitions\n",
    "\n",
    "triplets = [(55, 305, 84), (55, 305, 84),(74, 600, 120),(55, 305, 84),(55, 305, 84),(55, 305, 84)]\n",
    "\n",
    "dico_repet = detect_continuous_repetitions(triplets)\n",
    "\n",
    "print(dico_repet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p_d': [], 'd_v': [[0, 1], [3, 4, 5]], 'p_v': [], 'p': [], 'd': [], 'v': []}\n"
     ]
    }
   ],
   "source": [
    "def detect_prioritized_repetitions(partition):\n",
    "    \"\"\"\n",
    "    D√©tecte les r√©p√©titions contigu√´s de doublets (p, d), (p, v), (d, v) \n",
    "    et les r√©p√©titions simples dans une liste de partition.\n",
    "    \"\"\"\n",
    "    repetitions = {\n",
    "        \"p_d\": [],\n",
    "        \"d_v\": [],\n",
    "        \"p_v\": [],\n",
    "        \"p\": [],\n",
    "        \"d\": [],\n",
    "        \"v\": []\n",
    "    }\n",
    "\n",
    "    n = len(partition)\n",
    "    used_indices = set()\n",
    "\n",
    "    def detect_repetition(key_func, existing_indices):\n",
    "        result = []\n",
    "        start = 0\n",
    "        for i in range(1, n):\n",
    "            if key_func(partition[i]) == key_func(partition[i - 1]) and i not in existing_indices:\n",
    "                continue\n",
    "            else:\n",
    "                if i - start > 1 and not any(j in existing_indices for j in range(start, i)):\n",
    "                    result.append(list(range(start, i)))\n",
    "                start = i\n",
    "        if n - start > 1 and not any(j in existing_indices for j in range(start, n)):\n",
    "            result.append(list(range(start, n)))\n",
    "        return result\n",
    "\n",
    "    # D√©tection des doublets\n",
    "    repetitions[\"p_d\"] = detect_repetition(lambda t: (t[0], t[1]), used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"p_d\"] for idx in group])\n",
    "\n",
    "    repetitions[\"d_v\"] = detect_repetition(lambda t: (t[1], t[2]), used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"d_v\"] for idx in group])\n",
    "\n",
    "    repetitions[\"p_v\"] = detect_repetition(lambda t: (t[0], t[2]), used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"p_v\"] for idx in group])\n",
    "\n",
    "    # D√©tection des r√©p√©titions simples\n",
    "    repetitions[\"p\"] = detect_repetition(lambda t: t[0], used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"p\"] for idx in group])\n",
    "\n",
    "    repetitions[\"d\"] = detect_repetition(lambda t: t[1], used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"d\"] for idx in group])\n",
    "\n",
    "    repetitions[\"v\"] = detect_repetition(lambda t: t[2], used_indices)\n",
    "\n",
    "    return repetitions\n",
    "\n",
    "#TEST\n",
    "\n",
    "partition = [(56, 305, 85), (55, 305, 85),(74, 600, 120),(53, 305, 85),(54, 305, 85),(51, 305, 85)]\n",
    "\n",
    "dico_repet = detect_prioritized_repetitions(partition)\n",
    "\n",
    "print(dico_repet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(74, 600, 120, 4), (51, 305, 85, 42)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def traiter_same_notes(partition):\n",
    "    \"\"\"\n",
    "    D√©tecte les triplets pr√©sents au moins deux fois dans la liste,\n",
    "    renvoie un dictionnaire avec leur nombre d'occurrences\n",
    "    et une liste sans aucune occurrence des triplets r√©p√©t√©s.\n",
    "\n",
    "    Args:\n",
    "        partition (list of tuples): Liste des triplets (p, d, v).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionnaire avec les triplets r√©p√©t√©s comme cl√©s et leur occurrence comme valeurs.\n",
    "        list: Liste des triplets sans aucune occurrence des r√©p√©titions.\n",
    "    \"\"\"\n",
    "    # Etape 1 : cr√©er la liste des triplets \n",
    "    liste_triplets = [quadruplet[:3] for quadruplet in partition]\n",
    "\n",
    "    # √âtape 1 : Compter les occurrences de chaque triplet\n",
    "\n",
    "    compteur = Counter(liste_triplets)\n",
    "    \n",
    "    # √âtape 2 : Construire un dictionnaire des triplets ayant des occurrences >= 2\n",
    "    dico_repetitions = {triplet: count for triplet, count in compteur.items() if count >= 2}\n",
    "    \n",
    "    # √âtape 3 : Construire une nouvelle liste en excluant les triplets dupliqu√©s\n",
    "    nouvelle_partition = [quadruplet for quadruplet in partition if quadruplet[:3] not in dico_repetitions]\n",
    "    \n",
    "    return dico_repetitions, nouvelle_partition\n",
    "\n",
    "\n",
    "\n",
    "partition = [(55, 305, 85,1), (55, 305, 85,2),(74, 600, 120,4),(55, 305, 85,8),(55, 305, 85,12),(51, 305, 85,42)]\n",
    "\n",
    "dico,liste = traiter_same_notes(partition)\n",
    "\n",
    "print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code harmonique\n",
    "#On doit le faire avant le reste\n",
    "\n",
    "def algo_harmoniques(partition) :\n",
    "    # Initialisation\n",
    "    dico_accords = {}  # Dictionnaire pour stocker les accords et leur valeur associ√©e\n",
    "    valeur_incr = 128  # Valeur de d√©part pour les accords\n",
    "    partition_accords = []  # Liste pour stocker la nouvelle partition avec accords\n",
    "    gain_total = 0  # Variable pour stocker le gain total\n",
    "\n",
    "    # Regrouper les quadruplets par start_time\n",
    "    accords_par_temps = defaultdict(list)\n",
    "    for quadruplet in partition:\n",
    "        pitch, duration, velocity, start_time = quadruplet\n",
    "        accords_par_temps[start_time].append(quadruplet)\n",
    "\n",
    "    # Parcourir les accords regroup√©s\n",
    "    for start_time, notes in accords_par_temps.items():\n",
    "        if len(notes) > 1:  # Il s'agit d'un accord si plusieurs notes partagent le m√™me start_time\n",
    "            # Cr√©er un tuple repr√©sentant l'accord (les pitches tri√©s pour garantir l'unicit√©)\n",
    "            pitches = tuple(sorted(note[0] for note in notes))\n",
    "\n",
    "            # Ajouter l'accord au dictionnaire s'il n'existe pas\n",
    "            if pitches not in dico_accords:\n",
    "                dico_accords[pitches] = valeur_incr\n",
    "                valeur_incr += 1\n",
    "\n",
    "            # Calculer le gain pour cet accord\n",
    "            gain = 20 * (len(notes) - 1)\n",
    "            gain_total += gain\n",
    "\n",
    "            # Cr√©er un seul quadruplet pour l'accord\n",
    "            duration = notes[0][1]  # Prendre la duration de la premi√®re note\n",
    "            velocity = notes[0][2]  # Prendre la velocity de la premi√®re note\n",
    "            partition_accords.append((dico_accords[pitches], duration, velocity, start_time))\n",
    "        else:\n",
    "            # Garder les notes seules inchang√©es\n",
    "            partition_accords.append(notes[0])\n",
    "\n",
    "    # Remplacer la partition originale\n",
    "    partition = partition_accords\n",
    "\n",
    "    return partition,gain_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estim_complexite(partition) :\n",
    "    \"\"\" partition : liste de tuples de 3 int. Chaque tuple repr√©sente une note\n",
    "    Cette fonction estime la complexit√© de la partition, √† partir des hypoth√®ses √©mises pr√©c√©demment\n",
    "    \"\"\"\n",
    "    worst_complexity = 42*len(partition) #Comme expliqu√© plus haut \n",
    "    #On commence par les accords\n",
    "    partition,gain_accords = algo_harmoniques(partition)\n",
    "    #d√©tecter les triplets identiques\n",
    "    same_triplets,partition_reduite = traiter_same_notes(partition)\n",
    "    #On utilisera le dictionnaire same_triplets, pour calculer la r√©duction de complexit√©, apr√®s\n",
    "\n",
    "    #d√©tecter les r√©p√©titions de d, p , v ou de doublets (p,v),(p,d) (d,v)\n",
    "    repetitions = detect_prioritized_repetitions(partition_reduite)\n",
    "\n",
    "    #Maintenant on va utiliser nos deux dictionnaires 'same_triplets' et repetitions pour calculer la r√©duction de complexit√©\n",
    "\n",
    "    #On commence par les triplets identiques \n",
    "    gain_triplets_identiques = sum((count - 1) * 28 for count in same_triplets.values())\n",
    "\n",
    "    #Maintenant gain sur les r√©p√©titions de doublet ou simple variable\n",
    "    # D√©finition des √©conomies par type\n",
    "    gains_par_type = {\n",
    "        \"p\": 7,\n",
    "        \"d\": 14,\n",
    "        \"v\": 7,\n",
    "        \"p_d\": 21,\n",
    "        \"p_v\": 14,\n",
    "        \"d_v\": 21\n",
    "    }\n",
    "    \n",
    "    gain_repetitions = 0\n",
    "    \n",
    "    # Boucle sur chaque type de r√©p√©tition\n",
    "    for type_repet, repetitions in repetitions.items():\n",
    "        for repetition in repetitions:\n",
    "            taille = len(repetition)  # Taille de la r√©p√©tition\n",
    "            if taille > 1:  # Les r√©p√©titions doivent √™tre d'au moins 2 notes\n",
    "                # Calcul des bits √©conomis√©s pour cette r√©p√©tition\n",
    "                bits_economises = (taille - 1) * gains_par_type[type_repet]\n",
    "                \n",
    "                # Bits pour encoder le type (4 bits) et la taille (log2(taille))\n",
    "                bits_ajoutes = 4 + math.ceil(math.log2(taille))\n",
    "                \n",
    "                # Gain net\n",
    "                gain_net = bits_economises - bits_ajoutes\n",
    "                gain_repetitions += gain_net\n",
    "\n",
    "    \n",
    "    #Et le calcul final\n",
    "    Complexity = worst_complexity - gain_triplets_identiques - gain_repetitions - gain_accords\n",
    "\n",
    "    return Complexity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explication des calculs**\n",
    "**Pour les triplets identiques :** \n",
    "\n",
    "On doit coder le triplet une seule fois, puis les positions. La complexit√© est alors de :\n",
    "C = 28 + 14 x nb_repetition_du_triplet. On √©conomise 28 bits √† chaque fois qu'on a un triplet identique en +. On encode 1 fois pour tous les nb_repetition_du_triplet de la partition. Donc on gagne 28x(nb_repetition_du_triplet - 1). Pour chaque triplet r√©p√©t√©.\n",
    "\n",
    "**Pour les r√©p√©titions de doublets ou simples variables :**\n",
    "\n",
    "On doit coder de quel type de r√©p√©tition il s'agit. 6 types de r√©p√©tition possibles, donc cette info se code sur 4 bits. C'est d'ailleurs le seul mot de 4 bits possible dans notre s√©quence, donc quand on voit un mot de 4 bits on sait qu'on a √† faire √† une r√©p√©tition. Il faut aussi encoder la taille de la r√©p√©tition : sur combien de notes la r√©p√©tition a lieu. Cette valeur vaut log2(taille_r√©p√©tition). En fonction de la ou les variables qui se r√©p√®tent on √©conomise plus ou moins de bits. p fait 7 bits donc les r√©p√©titions de p √©conomisent 7 bits √† chaque fois (moins tous ceux qu'on a du ajouter pour encoder la r√©p√©tition). Pour une r√©p√©tition de d on √©conomise 14 bits √† chaque fois. Pour des doublets on √©conomise sur chaque variable. Si on a une r√©p√©tion d_p, on √©conomise 7 + 14 = 21 bits par r√©p√©tition. On encode donc cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Tests\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m partition_test \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mtriplets\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mComplexit√© estim√©e\u001b[39m\u001b[39m\"\u001b[39m,estim_complexite(partition_test))\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mworst_case complexity = \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m42\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(partition_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Tests\n",
    "partition_test = df[\"triplets\"][0]\n",
    "\n",
    "\n",
    "print(\"Complexit√© estim√©e\",estim_complexite(partition_test))\n",
    "print(\"worst_case complexity = \",42*len(partition_test))\n",
    "\n",
    "print(\"ratio de compression via ma m√©thode = \",(estim_complexite(partition_test))/(42*len(partition_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul de la compression zip\n",
    "\n",
    "def calculer_ratio_compression(partition):\n",
    "    \"\"\"\n",
    "    Calcule le ratio de compression d'une partition de triplets en utilisant zlib.\n",
    "\n",
    "    Args:\n",
    "        partition (list of tuples): Liste de triplets (p, d, v).\n",
    "\n",
    "    Returns:\n",
    "        float: Ratio de compression (valeur entre 0 et 1, o√π plus proche de 0 = meilleure compression).\n",
    "    \"\"\"\n",
    "    # √âtape 1 : Convertir la partition en cha√Æne de caract√®res\n",
    "    partition_str = \",\".join(f\"{t[0]}_{t[1]}_{t[2]}\" for t in partition)\n",
    "    \n",
    "    # √âtape 2 : Compresser la cha√Æne avec zlib\n",
    "    partition_bytes = partition_str.encode('utf-8')  # Conversion en bytes\n",
    "    compressed_bytes = zlib.compress(partition_bytes)\n",
    "    \n",
    "    # √âtape 3 : Calculer le ratio de compression\n",
    "    ratio_compression = len(compressed_bytes) / len(partition_bytes)\n",
    "    \n",
    "    return ratio_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexit√© estim√©e 27298\n",
      "worst_case complexity =  55944\n",
      "ratio de compression via ma m√©thode =  0.48795223795223797\n",
      "ratio de compression avec zip =  0.08481277040131284\n"
     ]
    }
   ],
   "source": [
    "#Tests\n",
    "partition_test = df[\"triplets\"][0]\n",
    "\n",
    "\n",
    "print(\"Complexit√© estim√©e\",estim_complexite(partition_test))\n",
    "print(\"worst_case complexity = \",42*len(partition_test))\n",
    "\n",
    "print(\"ratio de compression via ma m√©thode = \",(estim_complexite(partition_test))/(42*len(partition_test)))\n",
    "print(\"ratio de compression avec zip = \",calculer_ratio_compression(partition_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[\"Notes\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mido import MidiFile\n",
    "\n",
    "# Fonction pour extraire les notes au format (p, d, v, t)\n",
    "def extract_note_data(midi_path):\n",
    "    note_data = []\n",
    "    midi = MidiFile(midi_path)\n",
    "    current_time = 0  # Temps accumul√© en ticks\n",
    "    for track in midi.tracks:\n",
    "        for msg in track:\n",
    "            if not msg.is_meta:\n",
    "                current_time += msg.time  # Temps accumul√©\n",
    "                if msg.type == 'note_on' and msg.velocity > 0:\n",
    "                    note_data.append((msg.note, 0, msg.velocity, current_time))\n",
    "    return note_data\n",
    "\n",
    "# Parcourir tous les fichiers MIDI\n",
    "extract_path = \"adl-piano-midi\"\n",
    "all_notes = []\n",
    "\n",
    "for root, _, files in os.walk(extract_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mid\") or file.endswith(\".midi\"):\n",
    "            midi_path = os.path.join(root, file)\n",
    "            notes = extract_note_data(midi_path)\n",
    "            all_notes.extend([(file, note) for note in notes])\n",
    "\n",
    "# Afficher un aper√ßu des notes extraites\n",
    "print(\"Exemple de notes extraites :\")\n",
    "print(all_notes[:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probl√®me : on a en r√©alit√© 4 variables, donc on doit refaire un dataset accurate. On essaie dans un nouveau Notebook**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partition : c'est une liste de triplets \n",
    "\n",
    "On s'en fout de la nature du triplet, tant qu'on a 3 valeurs\n",
    "\n",
    "On va juste convertir les bonnes donn√©es, en triplet. Et voila \n",
    "\n",
    "Pour les harmoniques, quand y'a un delta_t √† 0 √ßa veut dire 2 notes sont jou√©es en m√™me temps. Si √ßa correspond √† un accord, alors on encode le nom de l'accord √† la place des deux notes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_TP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dac106c35ce3d047d16e564b0a4c64d2054fbff410f883fbe9cca57677e1729f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
