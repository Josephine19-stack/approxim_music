{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import Counter\n",
    "import math\n",
    "import zlib\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"music_metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(notes_dict):\n",
    "    pitches = [note[0] for note in notes_dict.values()]\n",
    "    durations = [note[1] for note in notes_dict.values()]\n",
    "    velocities = [note[2] for note in notes_dict.values()]\n",
    "    return pitches, durations, velocities\n",
    "def calculate_entropy(sequence):\n",
    "    counts = Counter(sequence)\n",
    "    probabilities = [count / len(sequence) for count in counts.values()]\n",
    "    return -sum(p * math.log2(p) for p in probabilities if p > 0)\n",
    "def calculate_compression_ratio(sequence):\n",
    "    # Convert the sequence to a string for compression\n",
    "    sequence_str = \",\".join(map(str, sequence))\n",
    "    compressed = zlib.compress(sequence_str.encode('utf-8'))\n",
    "    return len(compressed) / len(sequence_str.encode('utf-8'))\n",
    "\n",
    "def calculate_metrix(df):\n",
    "    complexity_scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        notes_dict = ast.literal_eval(row[\"Notes\"])  # Convert string back to dictionary\n",
    "        pitches, durations, velocities = extract_features(notes_dict)\n",
    "\n",
    "        metrics = {\n",
    "        \"pitch_entropy\": calculate_entropy(pitches),\n",
    "        \"duration_entropy\": calculate_entropy(durations),\n",
    "        \"velocity_entropy\": calculate_entropy(velocities),\n",
    "        \"pitch_compression\": calculate_compression_ratio(pitches),\n",
    "        \"duration_compression\": calculate_compression_ratio(durations),\n",
    "        \"velocity_compression\": calculate_compression_ratio(velocities),\n",
    "        }\n",
    "\n",
    "        complexity_scores.append(metrics)\n",
    "\n",
    "    # Add the complexity column to the dataframe\n",
    "    return complexity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       {'pitch_entropy': 4.039494663005557, 'duration...\n",
      "1       {'pitch_entropy': 3.3698373541095803, 'duratio...\n",
      "2       {'pitch_entropy': 3.6740738464145557, 'duratio...\n",
      "3       {'pitch_entropy': 4.404917585176534, 'duration...\n",
      "4       {'pitch_entropy': 4.484162704131576, 'duration...\n",
      "                              ...                        \n",
      "2031    {'pitch_entropy': 4.346988230461985, 'duration...\n",
      "2032    {'pitch_entropy': 4.517722105737881, 'duration...\n",
      "2033    {'pitch_entropy': 4.0377172942187, 'duration_e...\n",
      "2034    {'pitch_entropy': 3.960525399817489, 'duration...\n",
      "2035    {'pitch_entropy': 4.226813284500464, 'duration...\n",
      "Name: Metrix, Length: 2036, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(output_directory)\n",
    "df[\"Metrix\"] = calculate_metrix(df)\n",
    "print(df[\"Metrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2036, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_notes_from_df(df):\n",
    "    # Cr√©e trois nouvelles colonnes pour les pitches, durations et velocities\n",
    "    df[\"pitches\"] = df[\"Notes\"].apply(lambda x: [note[0] for note in ast.literal_eval(x).values()])\n",
    "    df[\"durations\"] = df[\"Notes\"].apply(lambda x: [note[1] for note in ast.literal_eval(x).values()])\n",
    "    df[\"velocities\"] = df[\"Notes\"].apply(lambda x: [note[2] for note in ast.literal_eval(x).values()])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = extract_notes_from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "#l = [df[\"pitches\"][0],df[\"durations\"][0],df[\"velocities\"][0]]\n",
    "\n",
    "\n",
    "print(df[\"pitches\"][0][0]) #df[\"pitches\"] est en 2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'y a que des partitions de piano dans le dataset, une seule piste √† chaque morceau/ligne (donc ce qu'on voulait nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Je veux des listes des triplets \n",
    "\n",
    "\n",
    "def extract_triplets(df):\n",
    "    \"\"\"\n",
    "    Convert the 'Notes' column in the DataFrame into a list of triplets (pitches, durations, velocities).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a 'Notes' column with dictionary-like strings.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with a new column 'triplets' containing the list of tuples.\n",
    "    \"\"\"\n",
    "    df[\"triplets\"] = df[\"Notes\"].apply(lambda x: [tuple(note) for note in ast.literal_eval(x).values()])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_triplets(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On encode notre musique en une s√©quence de mots, √©crits en bits. Les mots sont s√©par√©s par des espaces.**\n",
    "\n",
    "S√©quence : position - p - d - v\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approche de la complexit√© de Kolmogorov\n",
    "En gros une note c'est un triplet (p,d,v) (pitch, duratio,velocity)\n",
    "Donc deux notes identiques c'est deux notes qui ont les m√™mes p,d,v\n",
    "Si on a deux m√™mes p,d,v alors on a juste √† √©crire la note une fois, et √† mettre ses 2 emplacements. C'est moins long que d'encoder deux fois l'emplacement et le p,d,v. Donc premier facteur de r√©duction de complexit√©\n",
    "\n",
    "\n",
    "Savoir qu'il y a plusieurs notes de m√™me p √ßa sert pas forc√©ment √† grand chose car il faut quand m√™me noter leur emplacement\n",
    "Mais quand plusieurs notes de m√™me p ou d ou v se suivent la c'est int√©ressant et √ßa fait diminuer la complexit√©\n",
    "Donc quand on a des notes qui se suivent avec m√™mes p ou d ou v, complexit√© diminue\n",
    "\n",
    "pareil si c'est pour des couples de var : si deux notes se suivent avec m√™me p,v (mais d diff√©rent) alors √ßa fait quand m√™me bien diminuer la complexit√© \n",
    "Algo : \n",
    "\n",
    "1) on imagine que notre code code toutes les notes uniques et sans aucunes r√©petitions de p,d,v √† droite ou √† gauche, avec leurs emplacements\n",
    "\n",
    "2) puis il prend celles qui se r√©p√®tentsur une ou 2 vars, et les codes ensemble\n",
    "\n",
    "3) puis il prend les notes identiques et code juste leur emplacement\n",
    "\n",
    "Si une note est √† la fois exactement √©gale √† une autre, et apparait dans une r√©p√©tition de p, alors comment on l'encode ? Ca c'est une bonne question (elle appartient aux notes de cat√©gorie 2 et 3 √† la fois)\n",
    "-> Pour l'instant on consid√®re que la m√©thode 3 est toujours plus efficace, donc on classe ce genre de note dans la classe 3\n",
    "\n",
    "--> En v√©rit√© √ßa va d√©pendre de la longueur de la r√©p√©tition d'une var. Si √ßa fait beaucoup diminuer la complexit√© des notes voisines alors il faudrait prendre encodage 2. Mais y a aussi un probl√®me avec cette esp√®ce de \"valeur\" de complexit√©. On fait des +1 -1 genre ?\n",
    "\n",
    "Pour l'instant oui "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus long encodage : chaque triplet et son emplacement "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taille de l'encodage d'un triplet (ùëù,ùëë,ùë£) : constante ùê∂_note\n",
    "Taille de l'encodage de la position : constant ùê∂_position\n",
    "nombre de notes : n \n",
    "Taille maximale de l'encodage : n x (ùê∂_note + ùê∂_position) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_length = np.mean([len(df[\"triplets\"][i]) for i in range(len(df[\"triplets\"]))])\n",
    "print(mean_length)\n",
    "\n",
    "max_length = np.max([len(df[\"triplets\"][i]) for i in range(len(df[\"triplets\"]))])\n",
    "print(max_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taille encodage p : p varie de 0 √† 127, il est donc √©crit sur 7 bits\n",
    "\n",
    "d en millisecondes, ne d√©passe pas 10 000 ms :  14 bits\n",
    "\n",
    "v varie de 0 √† 127 : 7 bits\n",
    "\n",
    "ùê∂_note = 28 bits\n",
    "\n",
    "la partition la plus longue comporte : 9824 notes\n",
    "9824 se code sur 14 bits\n",
    "donc la position se code sur 14 bits\n",
    "\n",
    "ùê∂_position = 14 bits\n",
    "\n",
    "Taille maximale de l'encodage = n x 42 bits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S√©quence :  p - d - v - position\n",
    "Soit :      7   14  7      14       en bits\n",
    "\n",
    "Si on voit plusieurs s√©quences de 14 bits d'affil√©es, c'est qu'on a un triplet identique √† plusieurs endroits, et qu'on encode √† la suite les positions\n",
    "\n",
    "(peut-√™tre que ce serait bien de pr√©ciser la position que dans ce cas d'ailleurs, car sinon la suite se lit comme une s√©quence, les notes sont cod√©es les unes apr√®s les autres selon leur ordre d'apparition, donc on connait d√©j√† leur position)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il faut avoir une mani√®re de pr√©ciser dans le code qu‚Äôon a une r√©p√©tition et la taille de la r√©p√©tition. Il y a 5 types de r√©p√©titions possibles : d, p , v ou de doublets (p,v) , (p,d) (d,v), √ßa se code sur 4 bits. Ca tombe bien rien ne fait 4 bits dans ce qui pr√©c√©de, donc dans notre code c√®s qu'on voit 4 bits, √ßa veut dire qu'il y a r√©p√©tition. Ca dit qu'est-ce qui est r√©p√©t√©. Puis ensuite √ßa donne le nombre de r√©p√©titions. Pas sur que ce 'quand tu vois un mot de 4 bits c'est que c'est pour pr√©ciser une r√©p√©tition donc tu sais ce que √ßa veut dire' soit tr√®s correct. On suppose que les mots sont s√©par√©s par des espaces. Est-ce qu'on peut faire cette hypoth√®se ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = df[\"triplets\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': [[0, 1], [3, 4, 5]], 'd': [[0, 1], [3, 4, 5]], 'v': [[0, 1], [3, 4, 5]], 'p_v': [[0, 1], [3, 4, 5]], 'p_d': [[0, 1], [3, 4, 5]], 'd_v': [[0, 1], [3, 4, 5]]}\n"
     ]
    }
   ],
   "source": [
    "def detect_continuous_repetitions(triplets):\n",
    "    \"\"\"\n",
    "    D√©tecte les r√©p√©titions contigu√´s dans une liste de triplets (p, d, v) \n",
    "    et les classe par type de r√©p√©tition.\n",
    "    \n",
    "    Args:\n",
    "        triplets (list of tuples): Liste des notes sous forme de triplets (p, d, v).\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionnaire contenant les r√©p√©titions d√©tect√©es sous forme de listes d'indices.\n",
    "    \"\"\"\n",
    "    repetitions = {\n",
    "        \"p\": [],       # R√©p√©titions de pitches\n",
    "        \"d\": [],       # R√©p√©titions de durations\n",
    "        \"v\": [],       # R√©p√©titions de velocities\n",
    "        \"p_v\": [],     # R√©p√©titions de (p, v)\n",
    "        \"p_d\": [],     # R√©p√©titions de (p, d)\n",
    "        \"d_v\": []      # R√©p√©titions de (d, v)\n",
    "    }\n",
    "    \n",
    "    n = len(triplets)\n",
    "    \n",
    "    # Fonction pour d√©tecter les r√©p√©titions sur une cl√© donn√©e\n",
    "    def detect_repetition(key_func):\n",
    "        result = []\n",
    "        start = 0  # D√©but d'une r√©p√©tition\n",
    "        for i in range(1, n):\n",
    "            if key_func(triplets[i]) == key_func(triplets[i - 1]):\n",
    "                continue  # La r√©p√©tition continue\n",
    "            else:\n",
    "                # Fin de la r√©p√©tition\n",
    "                if i - start > 1:  # Une r√©p√©tition doit avoir au moins 2 √©l√©ments\n",
    "                    result.append(list(range(start, i)))\n",
    "                start = i  # Nouvelle r√©p√©tition\n",
    "        # Ajouter la derni√®re r√©p√©tition\n",
    "        if n - start > 1:\n",
    "            result.append(list(range(start, n)))\n",
    "        return result\n",
    "    \n",
    "    # Appliquer la d√©tection pour chaque type\n",
    "    repetitions[\"p\"] = detect_repetition(lambda t: t[0])  # R√©p√©titions sur p\n",
    "    repetitions[\"d\"] = detect_repetition(lambda t: t[1])  # R√©p√©titions sur d\n",
    "    repetitions[\"v\"] = detect_repetition(lambda t: t[2])  # R√©p√©titions sur v\n",
    "    repetitions[\"p_v\"] = detect_repetition(lambda t: (t[0], t[2]))  # R√©p√©titions sur (p, v)\n",
    "    repetitions[\"p_d\"] = detect_repetition(lambda t: (t[0], t[1]))  # R√©p√©titions sur (p, d)\n",
    "    repetitions[\"d_v\"] = detect_repetition(lambda t: (t[1], t[2]))  # R√©p√©titions sur (d, v)\n",
    "    \n",
    "    return repetitions\n",
    "\n",
    "triplets = [(55, 305, 84), (55, 305, 84),(74, 600, 120),(55, 305, 84),(55, 305, 84),(55, 305, 84)]\n",
    "\n",
    "dico_repet = detect_continuous_repetitions(triplets)\n",
    "\n",
    "print(dico_repet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p_d': [], 'd_v': [[0, 1], [3, 4, 5]], 'p_v': [], 'p': [], 'd': [], 'v': []}\n"
     ]
    }
   ],
   "source": [
    "def detect_prioritized_repetitions(partition):\n",
    "    \"\"\"\n",
    "    D√©tecte les r√©p√©titions contigu√´s de doublets (p, d), (p, v), (d, v) \n",
    "    et les r√©p√©titions simples dans une liste de partition.\n",
    "    \"\"\"\n",
    "    repetitions = {\n",
    "        \"p_d\": [],\n",
    "        \"d_v\": [],\n",
    "        \"p_v\": [],\n",
    "        \"p\": [],\n",
    "        \"d\": [],\n",
    "        \"v\": []\n",
    "    }\n",
    "\n",
    "    n = len(partition)\n",
    "    used_indices = set()\n",
    "\n",
    "    def detect_repetition(key_func, existing_indices):\n",
    "        result = []\n",
    "        start = 0\n",
    "        for i in range(1, n):\n",
    "            if key_func(partition[i]) == key_func(partition[i - 1]) and i not in existing_indices:\n",
    "                continue\n",
    "            else:\n",
    "                if i - start > 1 and not any(j in existing_indices for j in range(start, i)):\n",
    "                    result.append(list(range(start, i)))\n",
    "                start = i\n",
    "        if n - start > 1 and not any(j in existing_indices for j in range(start, n)):\n",
    "            result.append(list(range(start, n)))\n",
    "        return result\n",
    "\n",
    "    # D√©tection des doublets\n",
    "    repetitions[\"p_d\"] = detect_repetition(lambda t: (t[0], t[1]), used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"p_d\"] for idx in group])\n",
    "\n",
    "    repetitions[\"d_v\"] = detect_repetition(lambda t: (t[1], t[2]), used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"d_v\"] for idx in group])\n",
    "\n",
    "    repetitions[\"p_v\"] = detect_repetition(lambda t: (t[0], t[2]), used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"p_v\"] for idx in group])\n",
    "\n",
    "    # D√©tection des r√©p√©titions simples\n",
    "    repetitions[\"p\"] = detect_repetition(lambda t: t[0], used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"p\"] for idx in group])\n",
    "\n",
    "    repetitions[\"d\"] = detect_repetition(lambda t: t[1], used_indices)\n",
    "    used_indices.update([idx for group in repetitions[\"d\"] for idx in group])\n",
    "\n",
    "    repetitions[\"v\"] = detect_repetition(lambda t: t[2], used_indices)\n",
    "\n",
    "    return repetitions\n",
    "\n",
    "#TEST\n",
    "\n",
    "partition = [(56, 305, 85), (55, 305, 85),(74, 600, 120),(53, 305, 85),(54, 305, 85),(51, 305, 85)]\n",
    "\n",
    "dico_repet = detect_prioritized_repetitions(partition)\n",
    "\n",
    "print(dico_repet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(55, 305, 85): 4} [(74, 600, 120), (51, 305, 85)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def traiter_triplets(partition):\n",
    "    \"\"\"\n",
    "    D√©tecte les triplets pr√©sents au moins deux fois dans la liste,\n",
    "    renvoie un dictionnaire avec leur nombre d'occurrences\n",
    "    et une liste sans aucune occurrence des triplets r√©p√©t√©s.\n",
    "\n",
    "    Args:\n",
    "        partition (list of tuples): Liste des triplets (p, d, v).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionnaire avec les triplets r√©p√©t√©s comme cl√©s et leur occurrence comme valeurs.\n",
    "        list: Liste des triplets sans aucune occurrence des r√©p√©titions.\n",
    "    \"\"\"\n",
    "    # √âtape 1 : Compter les occurrences de chaque triplet\n",
    "    compteur = Counter(partition)\n",
    "    \n",
    "    # √âtape 2 : Construire un dictionnaire des triplets ayant des occurrences >= 2\n",
    "    dico_repetitions = {triplet: count for triplet, count in compteur.items() if count >= 2}\n",
    "    \n",
    "    # √âtape 3 : Construire une nouvelle liste en excluant les triplets dupliqu√©s\n",
    "    liste_sans_repetitions = [triplet for triplet in partition if compteur[triplet] == 1]\n",
    "    \n",
    "    return dico_repetitions, liste_sans_repetitions\n",
    "\n",
    "\n",
    "\n",
    "partition = [(55, 305, 85), (55, 305, 85),(74, 600, 120),(55, 305, 85),(55, 305, 85),(51, 305, 85)]\n",
    "\n",
    "dico,liste = traiter_triplets(partition)\n",
    "\n",
    "print(dico,liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estim_complexite(partition) :\n",
    "    \"\"\" partition : liste de tuples de 3 int. Chaque tuple repr√©sente une note\n",
    "    Cette fonction estime la complexit√© de la partition, √† partir des hypoth√®ses √©mises pr√©c√©demment\n",
    "    \"\"\"\n",
    "    worst_complexity = 42*len(partition) #Comme expliqu√© plus haut \n",
    "    #d√©tecter les triplets identiques\n",
    "    same_triplets,partition_reduite = traiter_triplets(partition)\n",
    "    #On utilisera le dictionnaire same_triplets, pour calculer la r√©duction de complexit√©, apr√®s\n",
    "\n",
    "    #d√©tecter les r√©p√©titions de d, p , v ou de doublets (p,v),(p,d) (d,v)\n",
    "    repetitions = detect_prioritized_repetitions(partition_reduite)\n",
    "\n",
    "    #Maintenant on va utiliser nos deux dictionnaires 'same_triplets' et repetitions pour calculer la r√©duction de complexit√©\n",
    "\n",
    "    #On commence par les triplets identiques \n",
    "    gain_triplets_identiques = sum((count - 1) * 28 for count in same_triplets.values())\n",
    "\n",
    "    #Maintenant gain sur les r√©p√©titions de doublet ou simple variable\n",
    "    # D√©finition des √©conomies par type\n",
    "    gains_par_type = {\n",
    "        \"p\": 7,\n",
    "        \"d\": 14,\n",
    "        \"v\": 7,\n",
    "        \"p_d\": 21,\n",
    "        \"p_v\": 14,\n",
    "        \"d_v\": 21\n",
    "    }\n",
    "    \n",
    "    gain_repetitions = 0\n",
    "    \n",
    "    # Boucle sur chaque type de r√©p√©tition\n",
    "    for type_repet, repetitions in repetitions.items():\n",
    "        for repetition in repetitions:\n",
    "            taille = len(repetition)  # Taille de la r√©p√©tition\n",
    "            if taille > 1:  # Les r√©p√©titions doivent √™tre d'au moins 2 notes\n",
    "                # Calcul des bits √©conomis√©s pour cette r√©p√©tition\n",
    "                bits_economises = (taille - 1) * gains_par_type[type_repet]\n",
    "                \n",
    "                # Bits pour encoder le type (4 bits) et la taille (log2(taille))\n",
    "                bits_ajoutes = 4 + math.ceil(math.log2(taille))\n",
    "                \n",
    "                # Gain net\n",
    "                gain_net = bits_economises - bits_ajoutes\n",
    "                gain_repetitions += gain_net\n",
    "\n",
    "    \n",
    "    #Et le calcul final\n",
    "    Complexity = worst_complexity - gain_triplets_identiques - gain_repetitions\n",
    "\n",
    "    return Complexity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explication des calculs**\n",
    "**Pour les triplets identiques :** \n",
    "\n",
    "On doit coder le triplet une seule fois, puis les positions. La complexit√© est alors de :\n",
    "C = 28 + 14 x nb_repetition_du_triplet. On √©conomise 28 bits √† chaque fois qu'on a un triplet identique en +. On encode 1 fois pour tous les nb_repetition_du_triplet de la partition. Donc on gagne 28x(nb_repetition_du_triplet - 1). Pour chaque triplet r√©p√©t√©.\n",
    "\n",
    "**Pour les r√©p√©titions de doublets ou simples variables :**\n",
    "\n",
    "On doit coder de quel type de r√©p√©tition il s'agit. 6 types de r√©p√©tition possibles, donc cette info se code sur 4 bits. C'est d'ailleurs le seul mot de 4 bits possible dans notre s√©quence, donc quand on voit un mot de 4 bits on sait qu'on a √† faire √† une r√©p√©tition. Il faut aussi encoder la taille de la r√©p√©tition : sur combien de notes la r√©p√©tition a lieu. Cette valeur vaut log2(taille_r√©p√©tition). En fonction de la ou les variables qui se r√©p√®tent on √©conomise plus ou moins de bits. p fait 7 bits donc les r√©p√©titions de p √©conomisent 7 bits √† chaque fois (moins tous ceux qu'on a du ajouter pour encoder la r√©p√©tition). Pour une r√©p√©tition de d on √©conomise 14 bits √† chaque fois. Pour des doublets on √©conomise sur chaque variable. Si on a une r√©p√©tion d_p, on √©conomise 7 + 14 = 21 bits par r√©p√©tition. On encode donc cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexit√© estim√©e 27298\n",
      "worst_case complexity =  55944\n",
      "ratio de compression via ma m√©thode =  0.48795223795223797\n"
     ]
    }
   ],
   "source": [
    "#Tests\n",
    "partition_test = df[\"triplets\"][0]\n",
    "\n",
    "\n",
    "print(\"Complexit√© estim√©e\",estim_complexite(partition_test))\n",
    "print(\"worst_case complexity = \",42*len(partition_test))\n",
    "\n",
    "print(\"ratio de compression via ma m√©thode = \",(estim_complexite(partition_test))/(42*len(partition_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul de la compression zip\n",
    "\n",
    "def calculer_ratio_compression(partition):\n",
    "    \"\"\"\n",
    "    Calcule le ratio de compression d'une partition de triplets en utilisant zlib.\n",
    "\n",
    "    Args:\n",
    "        partition (list of tuples): Liste de triplets (p, d, v).\n",
    "\n",
    "    Returns:\n",
    "        float: Ratio de compression (valeur entre 0 et 1, o√π plus proche de 0 = meilleure compression).\n",
    "    \"\"\"\n",
    "    # √âtape 1 : Convertir la partition en cha√Æne de caract√®res\n",
    "    partition_str = \",\".join(f\"{t[0]}_{t[1]}_{t[2]}\" for t in partition)\n",
    "    \n",
    "    # √âtape 2 : Compresser la cha√Æne avec zlib\n",
    "    partition_bytes = partition_str.encode('utf-8')  # Conversion en bytes\n",
    "    compressed_bytes = zlib.compress(partition_bytes)\n",
    "    \n",
    "    # √âtape 3 : Calculer le ratio de compression\n",
    "    ratio_compression = len(compressed_bytes) / len(partition_bytes)\n",
    "    \n",
    "    return ratio_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests\n",
    "partition_test = df[\"triplets\"][0]\n",
    "\n",
    "\n",
    "print(\"Complexit√© estim√©e\",estim_complexite(partition_test))\n",
    "print(\"worst_case complexity = \",42*len(partition_test))\n",
    "\n",
    "print(\"ratio de compression via ma m√©thode = \",(estim_complexite(partition_test))/(42*len(partition_test)))\n",
    "print(\"ratio de compression avec zip = \",calculer_ratio_compression(partition_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_TP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dac106c35ce3d047d16e564b0a4c64d2054fbff410f883fbe9cca57677e1729f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
